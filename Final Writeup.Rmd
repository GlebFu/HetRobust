---
title: 'Replication: A df Approximation for a t-statistic with heterogeneous variance'
author: "Gleb Furman"
date: "May 14, 2015"
output: html_document
---

###Introduction
Lipsitz and Ibrahim (1999) sought to investigate the robustness of ordinary least squares (OLS) linear regression when the assumption of homoscedasticity is violated. This assumption is difficult to test when sample sizes are small and OLS parameter standard errors, if left unadjusted, are biased and inconsistent. Although transforming the response and covariates can result in a regression model with constant variance, transformations often result in results that are difficult to interpret. Jackknife methods and estimated generalized least squares (EGLS) estimators are also often used in such cases to estimate variance and bias, however even when variance is modeled correctly, small sample sizes can lead to unstable estimates and low confidence interval coverage rates. The authors therefore propose the use of ordinary least squares estimation with a robust variance as well as a degrees-of-freedom correction. The authors compared the results of the following four conditions:

1. OLS
 + $\hat{\sigma}_i^2 = \hat{\sigma}^2$
 + $df_p = n-p$
2. OLS
 + $\hat{\sigma}_i^2 = e_i^2/1-h_i$
 + $df_p = n-p$
3. OLS
 + $\hat{\sigma}_i^2 = e_i^2/1-h_i$
 + $df_p = \hat{f}_p$
4. EGLS
 + $\hat{\sigma}_i^2 = \hat{a}_0 + \hat{a}_1x_p$
 + $df_p = n-p$
 
 The current study seeks to replicate the first three conditions.

```{r, cache = T}
library(devtools)
library(sandwich)
library(psych)
library(stringr)
library(plyr)
library(Pusto)
library(stargazer)
library(dplyr)
library(knitr)
library(reshape2)
library(htmlTable)
library(microbenchmark)
#install_github("jepusto/Pusto")

rm(list = ls())
```

###Methods

```{r, cache = T}

```

####Data-Generating Model
The data-generating function (`gen_mod`) returns a list of values given three specifications: sample size (`n`, integer), heteroscedasticity (`ht`, boolean), and a vector of 3 $\beta$ coefficients (`B`, integer). The responses are fixed (1,1.5,2,2.5,3,3.5,4,5,6,7,8,10), therefore `n` must be a multiple of 12. If `ht` is false, the variance of the error (`e_var`) is set to 1. If true, `e_var` is set to the response string, such that $\epsilon_i$ ~ _N_(0,$x_i$). Error values (`E`) are randomly selected from a normal distribution with standard deviation equal to sqrt(`e_var`). Responses (`Y`) are then generated with the following formula: $Y = \beta_0 + \beta_1x + \beta_2x^2 + e$. The returned list contains the following values:

* `X` - A matrix of covariate values
* 'Y' - A vector of responses
* 'B' - A vector of known parameters
* 'invX' - The pseudoinverse of X
* `H` - A hat matrix
* `h` - The diagonal of the hat matrix
* `I` - An $n*n$ identity matrix 
* `W` - A vector of $1/sqrt(1-h)$
* 'w' - A vector of $1-h$
* `e` - A vector of model residuals
* 'coefs' - A fector of estimated parameters
* `n` - Number of observations
* `p` - Number of parameters
* 'M' - The inverse of the transposed X matrix multiplied by the X matrix

X = X, Y = Y, B = B, invX = invX, H = H, h = h, I = I, W = W, w = w, 
              e = e, coefs = coefs, n = n, p = p, M = M

```{r, cache = T}
gen_mod <- function(n = 12, ht = T, B = c(0, .4, -.25)) {
  
  X0 <- 1
  X1 <- rep(c(1,1.5,2,2.5,3,3.5,4,5,6,7,8,10), n/12)
  X2 <- X1^2
  
  X <- cbind(X0, X1, X2)
  
  E_var = 1
  if(ht) E_var <- X1
    
  E <- rnorm(n, 0, sqrt(E_var))
  Y <- t(B %*% t(X) + E)
  
  n <- nrow(X)
  p <- ncol(X)
  
  M <- solve(t(X) %*% X)
  invX <- M %*% t(X)
  coefs <- invX %*% Y
  e <- Y - X %*% coefs
  
  H <- X %*% invX
  h <- diag(H)
  I <- diag(1, n)
  W <- 1 / sqrt(1 - h)
  w <- 1 - h
  
  vars <- list(X = X, Y = Y, B = B, invX = invX, H = H, h = h, I = I, W = W, w = w, 
              e = e, coefs = coefs, n = n, p = p, M = M)
  
  return(vars)
}

#Demo
test_mod <- gen_mod(48, F, c(0, .4, -.25))

```

####Estimation Procedures
The estimation procedures consist of two functions: `f_p`, and `estimate`. `f_p` uses the Satterthwaite approximation to estimate the degrees-of-freedom for a given coefficient, and returns the estimated df. As an arguement it takes `i` which serves to indicate the appropriate coefficient. This function requires that the list generated by `gen_mod` is attached prior to being called.  


```{r, cache = T}
f_p <- function(i) {

  c <- invX[i,]
  A <- diag((W * c)^2)
    
  var_B <- t(e) %*% A %*% e
  
  o4 <- e^4 / (3 * (1-h)^2)
  o2o2 <- e^2 %*% t(e)^2 / (2*H^2 + (1-h) %*%t (1-h))
  diag(o2o2) <- o4
  sigma_hat <- o2o2
  B <- ((I-H) %*% A %*% (I-H))
  
  num <- ((var_B)^2)
  den <- sum(as.vector(t(B)) * as.vector(B * sigma_hat))
  
  return(num/den)
}

#Demo
attach(test_mod)
sapply(1:p, f_p)
detach(test_mod)

```

The second function, `estimate`, is the main estimation driver function. It takes two arguments: the `gen_mod` generated list of values (`model`), and a condition to determine estimation `design`. The `model` is attached for simplicity. Using a switch function to determine the appropriate caculations given the condition, standard errors `sd_e` and degrees-of-freedom `df` are calculated for each parameter and returned in a list to `sdf`. t-statistics `t` and confidence intervals `ci` are then calculated and placed in a list `cidf`. `estimate` then detaches `model` and returns `cidf`.

```{r, cache = T}
estimate <- function(design, model) {
  attach(model)
  
  sdf <- switch(design,
                "HC2fp" = list(sd_e = sqrt(diag(M %*% t(X) %*% diag(as.vector(e^2/w)) %*% X %*% M)),
                               df = sapply(1:p, f_p)), 
                "HC2df" = list(sd_e = sqrt(diag(M %*% t(X) %*% diag(as.vector(e^2/w)) %*% X %*% M)),
                               df = rep(n-p,3)), 
                "OLSdf" = list(sd_e = sqrt(diag(sum(e^2/(n-p)) * M)),
                               df = rep(n-p,3)))   

  t <- qt(.975, sdf$df)
  
  ci <- t(cbind(lb = coefs, ub = coefs)) + matrix(c(-1,1)) %*% (t*sdf$sd_e)
  dimnames(ci)[[1]] <- c("lb", "ub")
  dimnames(ci)[[2]] <- paste(rep("B", p),0:(p-1), sep = "")
  
  cidf = list(ci = ci, df = sdf$df)
  
  detach(model)
  
  return(cidf)
}

#Demo
testimate <- sapply(c("OLSdf", "HC2df", "HC2fp"), estimate, test_mod)
testimate
testimate[,"OLSdf"]
testimate["ci",]
testimate["df",]

```

####Performance Criteria
Performance is determined using the main `performance` function and two helper functions: `coverage` and `cilength`. The `performance` function takes as its arguements `i`, an index specifying the condition for which to run calculations, `results`, a matrix of lists generated by the replication function, and `B`, a vector of known parameters. The following values are calculated:

* `mean_coverage` - Mean confidence interval coverage
* `var_coverage`  - Variance of the confidence interval coverage
* `mean_cilength` - Mean confidence interval length
* `var_cilength`  - Variance of the confidence interval length
* `mean_df`       - Mean estimated degrees-of-freedom
* `var_df`        - Variance of the estimated degrees-of-freedom

These values are then returned as a data frame object with parameters and conditions labeled appropriately.

```{r, cache = T}
coverage <- function(ci, B) {
  (B > ci["lb",]) * (B < ci["ub",])
}

cilength <- function(ci) ci["ub",] - ci["lb",]

performance <- function(i, results, B) {
  results <- results[, i, ]
  
  coverage <- laply(.data = results["ci",], .fun = coverage, B)
  mean_coverage <- colMeans(coverage)
  var_coverage <- apply(coverage, 2, var)
  
  cilength <-laply(.data = results["ci",], .fun = cilength)
  mean_cilength <- colMeans(cilength)
  var_cilength <- apply(cilength, 2, var)
  
  df <- matrix(unlist(results["df",]), ncol = length(B))
  mean_df <- colMeans(df)
  var_df <- apply(df, 2, var)
  
  p <- length(B)
  condition <- rep(i, p)
  parameters <- paste(rep("B", p),0:(p-1), sep = "")
  
  perf <- as.data.frame(cbind(mean_coverage, 
                              var_coverage, 
                              mean_cilength, 
                              var_cilength, 
                              mean_df, 
                              var_df), 
                        row.names = NULL, 
                        stringsAsFactors = F)
  perf$condition <- condition
  perf$parameter <- parameters
  return(perf)
}

#Demo
testrep <- replicate(10, {
                          model <- gen_mod()
                          estimates <- sapply(c("HC2fp", "OLSdf"), estimate, model)
                          return (estimates)
                        })
testrep
testrep[, "OLSdf",]
testrep["ci", , ]

testperf <- lapply(c("HC2fp", "OLSdf"), performance, testrep, c(0, .4, -.25))
testperf
do.call("rbind", testperf)
```

####Simulation Driver
The simulation drive, `runSim`, takes 8 design factors:

* `iterations` - Number of iterations to be simulated
* `n`   - Sample size (integer)
* `ht`  - Heteroscedastity (boolean)
* `B0`  - First coefficient (integer)
* `B1`  - Second coefficient (integer)
* `B2`  - Third coefficient (integer)
* `cond`- String of conditions separated by a "space" (character)
* `seed`- Seed, random if not passed (integer)

The function first separatesthe `cond` string into a vector of characters `conditions`. Based on the number of iterations, a replication function is called which generates a list of values (`model`) using `gen_mod`, passing through the sample size, whether or not heteroscedasticity should be included, and a vector of the coefficients. For each condition, estimate is called and `model` is passed as an arguement. Next, for each condition, performance is called with replication results `reps` and a vector of known parameters passed as arguements. This results in a list of performance measures for each condition, which is then merged into a signle data frame and returned.

```{r, cache = T}
runSim <- function(iterations, n, ht, B0, B1, B2, cond, seed = NULL) {
  conditions <- unlist(strsplit(cond, " ")) 
  
  if (!is.null(seed)) set.seed(seed)
  
  reps <- replicate(iterations, {
                  model <- gen_mod(n, ht, c(B0, B1, B2))
                  estimates <- sapply(conditions, estimate, model)
                  return (estimates)
                })
  
  perf <- lapply(conditions, performance, reps, c(B0, B1, B2))
  
  perf <- do.call("rbind", perf)
  
  return(perf)
}

#Demo
testrun <- runSim(iterations = 10,
                   n = 12,
                   ht = T,
                   B0 = 0,
                   B1 = .4,
                   B2 = -.25,
                   cond = "OLSdf HC2df HC2fp")
testrun

```


####Experimental Design
Lipsitz and Ibrahim were interested in three outcome variables under conditions of heterogeneous and homogeneous variance (`ht`): confidence interval coverage rate, estimated degrees-of-freedom, and confidence interval length. These outcomes were investigating by manipulating the estimation of the error variance (`var`) and the degrees-of-freedom (`df`) used in calculating the t-statistic. Sample size was also manipulated (`m`). The authors called for a fixed set of 12 responses which are included in the `gen_mod` function, as well as 3 coefficients with a fixed set of values (`B0`, `B1`, `B2`). 1825 `iterations` were run in the original study under each condition. For the current study, a new random seed was generated for each combination of sample size and presence of heterscedasticity.
```{r, cache = T}
set.seed(20150602)

design_factors <- list(n = c(12,24,48), 
                       ht = c(T,F), 
                       B0 = 0, 
                       B1 = .4, 
                       B2 = -.25, 
                       cond = c("OLSdf HC2df HC2fp"))
params <- expand.grid(design_factors, stringsAsFactors = F)
params$iterations <- 1825
params$seed <- round(runif(nrow(params)) * 2^30)
#Demo
params


```

###Results
```{r, cache = T}
source_obj <- ls()
cluster <- start_parallel(source_obj)

system.time(results <- mdply(params, .fun = runSim, .parallel = TRUE))

stopCluster(cluster)

```

```{r, cache = T}
estimates <- select(results, n, ht, condition, parameter, mean_coverage, mean_cilength, mean_df)
```

```{r, cache = T}
estimates$mean_coverage <- round(estimates$mean_coverage,3)*100
estimates$mean_cilength <- round(estimates$mean_cilength,2)/2
estimates$mean_df <- round(estimates$mean_df, 2)

names(estimates) <- c("n" , "ht" , "Condition" , "Parameter" , "Cov" , "Len" , "df")
estimates <- reshape(estimates, 
                    timevar = "Parameter", 
                    idvar =  c("n" , "ht" , "Condition"),
                    direction = "wide")
estimates <- estimates[,c("n" , "ht" , "Cov.B0", "Cov.B1", "Cov.B2", 
                          "Len.B0", "Len.B1", "Len.B2", "df.B0", "df.B1", "df.B2", 
                          "Condition")]

paper <- read.csv("data/Paper Results.csv")

names(estimates) <- names(paper)

difference <- estimates
difference[,3:11] <- round(select(estimates, B0_Cov:B2_df) - select(paper, B0_Cov:B2_df),3)
#MCSE <- cbind(sqrt(select(estimates, B0_Cov:B2_Cov)*(100-select(estimates, B0_Cov:B2_Cov))/1825), sqrt(select(estimates, B0_Len:B2_Len)^2/1825))

#val_MCSE <- matrix(paste(unlist(select(difference, B0_Cov:B2_Len), use.names = F), " (", round(unlist(MCSE,use.names = F), 3), ")", sep = ""),ncol = 6)
#difference[,5:10] <- val_MCSE

#bold <- difference[,5:10] > MCSE
#difference[,5:10][bold] <- paste("**",difference[,5:10][bold],"**", sep = "")
```

```{r, cache = T}
rslt <- function(data, title) {
  data <- reshape(data, varying = 3:11, sep = "_", direction = "long")
  data <- melt(select(data, n:B2), measure.vars = c("B0", "B1", "B2"), variable.name = "coefficients")
  data <- dcast(data, ... ~ ht + Condition)
  names(data) <- c("N", "Measure", "Coefficient", "HM HC2 n-p", "HM HC2 F_p", "HM Sd_e n-p", "HT HC2 n-p", "HT HC2 F_p", "HT Sd_e n-p")
  
  
  rslttbl <- arrange(data, Coefficient, N, Measure)
  rslttbl$Parameter <- rep(" ", nrow(rslttbl))
  rslttbl$Est <- rslttbl$Parameter
  rslttbl <- rslttbl[,c("Parameter", 
                      "Coefficient", 
                      "N", 
                      "Measure", 
                      "Est",  
                      "HT Sd_e n-p",
                      "HT HC2 n-p", 
                      "HT HC2 F_p",
                      "HM Sd_e n-p", 
                      "HM HC2 n-p",  
                      "HM HC2 F_p")]
  rslttbl[1,6] <- paste(rslttbl[1,6],"&dagger;", sep = "")
  rslttbl[2,6] <- paste(rslttbl[2,6],"&Dagger;", sep = "")
  rslttbl[3,6] <- paste(rslttbl[3,6],"&sect;", sep = "")
  
  col1 <- c("Parameter", "n", " ", "Heteroscedasticity", "Homoscedasticity", NA)
  col2 <-c("", 
           "$\\hat{\\sigma}_i^2 =$",
           "$\\hat{\\sigma}_i^2$", 
           "$e_i^2/(1-h_i)$", 
           "$\\hat{\\sigma}_i^2$", 
           "$e_i^2/(1-h_i)$")
  col3 <- c(" ", 
            " ", 
            "$df_p =$", 
            "&nbsp;&nbsp;$n-p$&nbsp;&nbsp;&nbsp;", 
            "&nbsp;&nbsp;$n-p$&nbsp;&nbsp;&nbsp;", 
            "&nbsp;&nbsp;&nbsp;$\\hat{f}_p$&nbsp;&nbsp;&nbsp;", 
            "&nbsp;&nbsp;$n-p$&nbsp;&nbsp;&nbsp;", 
            "&nbsp;&nbsp;$n-p$&nbsp;&nbsp;&nbsp;", 
            "&nbsp;&nbsp;&nbsp;$\\hat{f}_p$&nbsp;&nbsp;&nbsp;")
  
  ncol1 <- c(1, 1, 1, 3, 3, NA)
  ncol2 <- c(2, 1, 1, 2, 1, 2)
  
  htmlTable(rslttbl[,-c(2,4)],
            rgroup = c("*$\\beta_0$*", "&nbsp;", "&nbsp;", "*$\\beta_1$*", "&nbsp;", "&nbsp;", "*$\\beta_2$*", "&nbsp;", "&nbsp;"),
            n.rgroup = rep(3,9),
            tfoot = c("&dagger;Coverage Probability", 
                      "&Dagger;Average Length of Confidence Interval", 
                      "&sect;Average Degrees-Of-Freedom"),
            cgroup = rbind(col1, col2),
            n.cgroup = rbind(ncol1, ncol2),
            caption = title,
            rnames = F,
            col.rgroup = c("none", "#F7F7F7"),
            header = col3)
}

```
Table 5 reports the findings of the current study. Table 6 reports the findings of Lipsitz and Ibrahim (1999) for comparison. Table 7 reports the differences between the current and original studies.

```{r, cache = T}
rslt(estimates , "Table 5: Current study's coverage probabilities, average lengths and estimated degrees-of-freedom")
rslt(paper , "Table 6: Lipsitz and Ibrahim (1999) coverage probabilities, average lengths and estimated degrees-of-freedom")
rslt(difference, "Table 7: Table 5 - Table 6 (MCSE)")
```

###Discussion
The design of the study is effective in showing a proof of concept, however it has many limitations that primarily have to do with generalization and real world applications. The method by which the response string is generated guarantees a fair range of error variance, since a random generation of a small set of responses risks an uneven spread or underepresentation of extreme values. However such a uniform distribution is unlikely to be found in real data. This is especially problematic in the larger sample sizes because the response string is simply doubled or quadrupled. Although it would provide a less sterile result, generating random responses strings might be a more realistic approach in the future.

The model used to compute the estimates requires that researchers using these methods are aware of the correct model specifications in order to have accurate model fit (i.e. the quadratic term in $\beta_2x_i^2$). Yet model fit is never examined. This limits the scope of the simulation results greatly. An extension of this research could investigate coverage rates when the model is misspecified or includes more sets of covariates.

###Gas Study Replication

```{r, cache = T}
gas <- read.csv("data/Gas Study.csv")
gaslm <- lm(Y ~ X1 + X2 + X3 + X4, data = gas)
summary(gaslm)

OLS <- function(Y, X) {
  X <- as.matrix(cbind(1,X))
  Y <- as.matrix(Y)
  
  M <- solve(t(X) %*% X)
  coefs <- (M %*% t(X) %*% Y)
  
  e <- Y - X %*% coefs
  
  n <- nrow(X)
  p <- ncol(X)
  df <- n-p
  
  sigma <- sum(e^2/(df))
  
  sd_e <- sqrt(diag(sigma * M))
  
  t_stat <- coefs/sd_e
  
  p_vals <- 2 * pt(abs(t_stat), df, lower.tail=FALSE)
  
  tbl <- round(data.frame(cbind(df, coefs, sd_e, t_stat, p_vals)),4)
  names(tbl) <- c("Degrees of Freedom", 
                  "Estimates", "Std. Error", 
                  "t-statistic", "p-value")
  rownames(tbl) <-  paste(rep("B", p),0:(p-1), sep = "")
  return(tbl)
}

HC2 <- function(Y, X) {
  X <- as.matrix(cbind(1,X))
  Y <- as.matrix(Y)
  
  M <- solve(t(X) %*% X)
  coefs <- (M %*% t(X) %*% Y)
  
  e <- Y - X %*% coefs
  
  n <- nrow(X)
  p <- ncol(X)
  df <- n-p
  
  H <- X %*% M %*% t(X)
  h <- diag(H)
  w <- 1 - h
  sigma <- diag(as.vector(e^2/w))

  sd_e <- sqrt(diag(M %*% t(X) %*% sigma %*% X %*% M))
  
  t_stat <- coefs/sd_e
  p_vals <- 2 * pt(abs(t_stat), df, lower.tail=FALSE)
  
  tbl <- round(data.frame(cbind(df, coefs, sd_e, t_stat, p_vals)),4)
  names(tbl) <- c("Degrees of Freedom", 
                  "Estimates", "Std. Error", 
                  "t-statistic", "p-value")
  rownames(tbl) <-  paste(rep("B", p),0:(p-1), sep = "")
  return(tbl)
}

HC2fp <- function(Y, X) {
  X <- as.matrix(cbind(1,X))
  Y <- as.matrix(Y)
  
  M <- solve(t(X) %*% X)
  coefs <- (M %*% t(X) %*% Y)
  
  e <- Y - X %*% coefs
  
  n <- nrow(X)
  p <- ncol(X)
  
  H <- X %*% M %*% t(X)
  h <- diag(H)
  w <- 1 - h
  W <- 1 / sqrt(1 - h)
  I <- diag(1, n)
  sigma <- diag(as.vector(e^2/w))

  df <- sapply(1:p, 
               f_p2, 
               invX = M %*% t(X), 
               W = W, 
               e = e, 
               h = h, 
               H = H, 
               I = I)

  sd_e <- sqrt(diag(M %*% t(X) %*% sigma %*% X %*% M))
  t_stat <- coefs/sd_e
  p_vals <- 2 * pt(abs(t_stat), df, lower.tail=FALSE)
  
  tbl <- round(data.frame(cbind(df, coefs, sd_e, t_stat, p_vals)),4)
  names(tbl) <- c("Degrees of Freedom", 
                  "Estimates", "Std. Error", 
                  "t-statistic", "p-value")
  rownames(tbl) <-  paste(rep("B", p),0:(p-1), sep = "")
  return(tbl)
}


f_p2 <- function(p, invX, W, e, h, H, I) {
  c <- invX[p,]
  A <- diag((W * c)^2)
    
  var_B <- t(e) %*% A %*%e
  
  o4 <- e^4 / (3 * (1-h)^2)
  o2o2 <- e^2 %*% t(e)^2 / (2*H^2 + (1-h) %*%t (1-h))
  diag(o2o2) <- o4
  sigma_hat <- o2o2
  B <- ((I-H) %*% A %*% (I-H))
  
  num <- ((var_B)^2)
  den <- sum(as.vector(t(B)) * as.vector(B * sigma_hat))
  
  return(num/den)
}

OLS(gas$Y, select(gas, X1:X4))
HC2(gas$Y, select(gas, X1:X4))
HC2fp(gas$Y, select(gas, X1:X4))

# read.csv("data/Gas Study.csv") %>%
#   select(X1, X2, X3, X4, Y) %>%
#   arrange(X1, X2, X3, X4, Y) -> 
#   gas
# library(alr4)
# select(sniffer, X1 = TankTemp, X2 = GasTemp, X3 = TankPres, X4 = GasPres, Y) %>%
#   arrange(X1, X2, X3, X4, Y) -> 
#   gas_big
# 
# gas$gas <- TRUE
# gas_big$sniff <- TRUE
# gas_merge <- merge(gas, gas_big, all = TRUE)
# gas_merge <- within(gas_merge, {
#   gas <- !is.na(gas)
#   sniff <- !is.na(sniff)
# })
# with(gas_merge, table(gas, sniff))
# subset(gas_merge, sniff==FALSE)
# subset(gas_merge, Y==52)
# gas_merge[with(gas_merge, Y==52 & gas),"X3"] <- 7.26
# 
# gaslm <- lm(I(Y/2) ~ X1 + X2 + X3 + X4, data = gas)
# summary(gaslm)
# summary(lm(Y ~ X1 + X2 + X3 + X4, data = subset(gas_merge, gas)))
```
